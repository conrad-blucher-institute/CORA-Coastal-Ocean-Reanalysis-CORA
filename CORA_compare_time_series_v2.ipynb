{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d6fc216-c8ff-4124-94f1-c8284f25f8f0",
   "metadata": {
    "id": "8d6fc216-c8ff-4124-94f1-c8284f25f8f0"
   },
   "source": [
    "# Time Series Comparison\n",
    "\n",
    "This notebook pulls in data from the NOAA CO-OPS NWLON stations and pulls in CORA data at those locations from the NOAA Open Data Dissemination (NODD) and plots water level time series for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b52450",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Update these values as necessary\n",
    "\n",
    "`station_id` is a list of NOAA ID's. One source of information is https://tidesandcurrents.noaa.gov/map/index.html?region=Texas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608e9b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ═══════════════════════════════════════════════════════════════\n",
    "#  CONFIGURATION - MODIFY THESE VALUES AS NEEDED\n",
    "# ═══════════════════════════════════════════════════════════════\n",
    "\n",
    "# NOAA ID's of stations to query\n",
    "station_id = ['8665530', '8774770', '8771450', '8775237', '8775296', '8773037'] #, '8775870']\n",
    "\n",
    "\n",
    "# Time period for data extraction\n",
    "start_year = '2022'\n",
    "start_month = '09'\n",
    "start_day = '01'\n",
    "\n",
    "end_year = '2022'\n",
    "end_month = '11'\n",
    "end_day = '01'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75784115-8273-47d0-8004-6ea1e68b96dd",
   "metadata": {},
   "source": [
    "## Import python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973908ab-5c69-4775-ad1f-dccafc8deef0",
   "metadata": {
    "id": "973908ab-5c69-4775-ad1f-dccafc8deef0"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import dask\n",
    "import intake\n",
    "# import xarray as xr\n",
    "import scipy.spatial as sp\n",
    "# import s3fs\n",
    "# import geopy.distance\n",
    "from scipy.spatial import KDTree\n",
    "# import folium\n",
    "# from folium import Marker\n",
    "# from folium.plugins import HeatMap, MarkerCluster\n",
    "# from branca.colormap import linear, LinearColormap\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40f7d54",
   "metadata": {},
   "source": [
    "### Define Utility functions\n",
    "DO NOT MODIFY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbf0ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def area(x1, y1, x2, y2, x3, y3):\n",
    "\n",
    "    return (abs((x1 * (y2 - y3) + x2 * (y3 - y1)\n",
    "                + x3 * (y1 - y2)) / 2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06bb651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_kd_tree(ds):\n",
    "    e = ds.element.values.astype(int)\n",
    "    emin1 = e-1\n",
    "    num_elems = len(e)\n",
    "    x_vals = ds.x.values\n",
    "    y_vals = ds.y.values\n",
    "\n",
    "    xe=np.mean(x_vals[emin1],axis=1)\n",
    "    ye=np.mean(y_vals[emin1],axis=1)\n",
    "    tree = sp.KDTree(np.c_[xe,ye])\n",
    "    areas = [area(x_vals[emin1[k][0]],y_vals[emin1[k][0]],\\\n",
    "                  x_vals[emin1[k][1]],y_vals[emin1[k][1]],\\\n",
    "                  x_vals[emin1[k][2]],y_vals[emin1[k][2]])for k in range(0, num_elems)]\n",
    "    return tree, areas, e, x_vals, y_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb27390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_triangle(x_vals, y_vals, e,lat,lon):\n",
    "    e = ds.element.values.astype(int)-1\n",
    "\n",
    "    k = 10\n",
    "    dist, ii = tree.query([lon,lat],k=k)\n",
    "    ii = ii\n",
    "    triangle_i = -1\n",
    "\n",
    "    for i in range(0,k):\n",
    "\n",
    "      a1 = area(lon,lat,\\\n",
    "                x_vals[e[ii[i]][0]],y_vals[e[ii[i]][0]],\\\n",
    "                x_vals[e[ii[i]][1]],y_vals[e[ii[i]][1]])\n",
    "\n",
    "      a2 = area(lon,lat,\\\n",
    "                x_vals[e[ii[i]][1]],y_vals[e[ii[i]][1]],\\\n",
    "                x_vals[e[ii[i]][2]],y_vals[e[ii[i]][2]])\n",
    "      a3 = area(lon,lat,\\\n",
    "                x_vals[e[ii[i]][0]],y_vals[e[ii][i][0]],\\\n",
    "                x_vals[e[ii[i]][2]],y_vals[e[ii][i][2]])\n",
    "\n",
    "      t_area = a1 + a2 + a3\n",
    "      if abs(t_area - areas[ii[i]]) < 0.00000001:\n",
    "        triangle_i = ii[i]+1\n",
    "        break\n",
    "    if(triangle_i == -1):\n",
    "        print(\"ERROR for \" ,lat,lon)\n",
    "    return triangle_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ef0505-ce20-4f42-895d-d0f9dfab4e6f",
   "metadata": {},
   "source": [
    "## Get CORA dataset files\n",
    "**Access the data on the NODD and initialize the available CORA datasets.** \n",
    "\n",
    "*This accesses a .yml file located on the NODD that shows which CORA output files are available to import.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ee33db-10b7-4cd1-887d-7b0aaced1d04",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09ee33db-10b7-4cd1-887d-7b0aaced1d04",
    "outputId": "370bff26-6e85-46df-c299-13bd494dfe3e"
   },
   "outputs": [],
   "source": [
    "# @title This accesses a .yml file located on the NODD that shows which CORA output files are available to import.\n",
    "catalog = intake.open_catalog(\"s3://noaa-nos-cora-pds/CORA_V1.1_intake.yml\",storage_options={'anon':True})\n",
    "list(catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4128bcaf-6e23-46d4-b0e9-d31b38567359",
   "metadata": {
    "id": "de2ecccc-4203-41d4-8d98-4ca8369433f0"
   },
   "source": [
    "**CORA-V1.1-fort.63: Hourly water levels <br>\n",
    "CORA-V1.1-swan_DIR.63: Hourly mean wave direction <br>\n",
    "CORA-V1.1-swan_TPS.63: Hourly peak wave periods <br>\n",
    "CORA-V1.1-swan_HS.63: Hourly significant wave heights <br>\n",
    "CORA-V1.1-Grid: Hourly water levels interpolated from model nodes to uniform 500-meter resolution grid <br>\n",
    "All datasets denoted as timeseries are optimized for pulling long time series (greater than a few days) <br>\n",
    "For up to a few days of data, use the regular dataset (not labeled timeseries)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2ecccc-4203-41d4-8d98-4ca8369433f0",
   "metadata": {
    "id": "de2ecccc-4203-41d4-8d98-4ca8369433f0"
   },
   "source": [
    "*Now, create an xarray dataset for the CORA data that you would like to use.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51cd6d9-b6ba-4f8d-8eb9-db5f17ebda33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f51cd6d9-b6ba-4f8d-8eb9-db5f17ebda33",
    "outputId": "1bd11d46-cbdb-463f-ada8-049b357a2d97"
   },
   "outputs": [],
   "source": [
    "ds = catalog[\"CORA-V1.1-fort.63\"].to_dask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d296b8-2ff2-42f2-9451-1d398162c44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stationpointsfile = 'C:\\\\Users\\\\John.Ratcliff\\\\CORA\\\\HSOFS_GEC_Stations.csv'\n",
    "# cora_stations = pd.read_csv(stationpointsfile)\n",
    "# cora_stations['id'] = cora_stations['id'].astype(str)\n",
    "# cora_stations.iloc[62]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b5c70a-0c8a-4913-af79-2173318eafb2",
   "metadata": {},
   "source": [
    "## Get NWLON station data\n",
    "\n",
    "**Create a dataframe of NWLON station ids and coordinates from the CO-OPS API where you want to do a comparison.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wt_sKI4hvfqw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "wt_sKI4hvfqw",
    "outputId": "35825902-eec7-47e6-a36f-aee33138a246"
   },
   "outputs": [],
   "source": [
    "base_url = 'https://api.tidesandcurrents.noaa.gov/mdapi/prod/webapi/stations/.json'\n",
    "params = {\n",
    "    'type': 'waterlevels',\n",
    "    'units': 'metric'\n",
    "}\n",
    "print(f'base_url: {base_url}, parameters: {params}')\n",
    "response = requests.get(base_url, params=params)\n",
    "content = response.json()\n",
    "\n",
    "stations = content['stations']\n",
    "stations_df = pd.DataFrame(stations)\n",
    "\n",
    "# Include station name along with id, lat, lng\n",
    "stations_df = stations_df[['id','name','lat','lng']]\n",
    "\n",
    "# limit to the list of stations specified in the configuration section\n",
    "stations_df = stations_df[stations_df['id'].isin(station_id)]\n",
    "\n",
    "stations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ed413d-13b8-415a-bc82-e43e83accab8",
   "metadata": {},
   "source": [
    "**Loop through the station list to grab water level hourly heights for each station. Create a pandas dataframe of the time series data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-jXyNgWIT8Ke",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "-jXyNgWIT8Ke",
    "outputId": "02a6e5fd-2523-440f-928f-a20be3c487bf"
   },
   "outputs": [],
   "source": [
    "\n",
    "base_url = 'https://api.tidesandcurrents.noaa.gov/api/prod/datagetter'\n",
    "\n",
    "for i in range(0,len(stations_df)):\n",
    "    station_id = stations_df.id.iloc[i]\n",
    "    print(f\"Requesting data for station {station_id}\")\n",
    "\n",
    "    params = {\n",
    "        'begin_date': f'{start_year}{start_month}{start_day}',\n",
    "        'end_date': f'{end_year}{end_month}{end_day}',\n",
    "        'station': station_id,\n",
    "        'product': 'hourly_height',\n",
    "        'datum': 'MSL',\n",
    "        'time_zone': 'gmt',\n",
    "        'units': 'metric',\n",
    "        'format': 'json'\n",
    "    }\n",
    "\n",
    "    print(f'base_url: {base_url}, parameters: {params}')\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    content = response.json()\n",
    "\n",
    "    # The API returns a list of dictionaries, each with scalar values.\n",
    "    # We need to convert this structure into a list of lists or a list of dictionaries with list values\n",
    "    # before creating a DataFrame.\n",
    "\n",
    "    # Extracting data for 'time' and 'height'\n",
    "    time_data = [d['t'] for d in content['data']]\n",
    "    tnc_data = [d['v'] for d in content['data']]\n",
    "\n",
    "    # Convert tnc_data to numeric using a list comprehension\n",
    "    tnc_data = [float(x) for x in tnc_data]\n",
    "\n",
    "    # Creating DataFrame if it's the first iteration\n",
    "    if i == 0:\n",
    "        df = pd.DataFrame({'time': time_data, 'tnc_' + stations_df.id.iloc[i]: tnc_data})\n",
    "    # Appending 'height' data to existing DataFrame for subsequent iterations\n",
    "    else:\n",
    "        df['tnc_' + stations_df.id.iloc[i]] = tnc_data  # Append new height column\n",
    "df.set_index('time', inplace=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b48dd3",
   "metadata": {},
   "source": [
    "## Calculate CORA water levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4003db3f",
   "metadata": {},
   "source": [
    "### Get CORA node Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1c69af-8bf3-450f-abe1-02b52ea217ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree, areas, e, x_vals, y_vals = define_kd_tree(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d166da-74e9-40da-bbc5-d2ac94aab026",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0GeIfkfN4ZQ8",
    "outputId": "97e1cc0c-cff5-4b06-c17d-3e02232d3e85"
   },
   "outputs": [],
   "source": [
    "# Extract node coordinates from the mesh\n",
    "\n",
    "node_coords = np.c_[ds.x.values, ds.y.values]\n",
    "\n",
    "kdtree = KDTree(node_coords) # Build the kdtree that can be queried for nearest neighbor nodes to a geographic point\n",
    "\n",
    "# Initialize\n",
    "elem = np.zeros((len(stations_df), 1), dtype=int)\n",
    "elem_nodes = np.zeros((len(stations_df), 3), dtype=int)\n",
    "query_point = np.zeros((len(stations_df), 2))  # Assuming you want 2 columns for lat and lon\n",
    "distances = np.zeros((len(stations_df), 3))    # Assuming you want 3 nearest neighbors\n",
    "nearest = np.zeros((len(stations_df), 3), dtype=int)  # Assuming you want 3 nearest neighbors\n",
    "dist = np.zeros((len(stations_df), 3), dtype=float)\n",
    "weights = np.zeros((len(stations_df), 3), dtype=float)\n",
    "\n",
    "# for i in range(0,len(stations_df)):\n",
    "for i in tqdm(range(len(stations_df)), desc=\"Processing stations\"):\n",
    "\n",
    "    elem[i,:] = find_triangle(x_vals,y_vals,e,stations_df.lat.iloc[i],stations_df.lng.iloc[i])\n",
    "    distances[i,:], nearest[i,:] = kdtree.query([stations_df.lng.iloc[i],stations_df.lat.iloc[i]], k=3)\n",
    "    nearest[i,:] = nearest[i,:] + 1\n",
    "\n",
    "    if elem[i]==-1:\n",
    "        elem_nodes[i,:] = nearest[i,:]\n",
    "    else:\n",
    "        elem_nodes[i,:] = e[elem[i]-1]\n",
    "\n",
    "    x_dist = stations_df.lng.iloc[i] - x_vals[elem_nodes[i,:]]\n",
    "    y_dist = stations_df.lat.iloc[i] - y_vals[elem_nodes[i,:]]\n",
    "    dist[i,:] = np.sqrt(x_dist * x_dist + y_dist * y_dist)\n",
    "\n",
    "    if np.any(dist[i,:] ==0):\n",
    "        weights[i,:] = np.where(dist[i,:] == 0, 1, 0)\n",
    "    else:\n",
    "        weights[i,:] = 1/dask.array.sqrt(x_dist * x_dist + y_dist * y_dist)\n",
    "\n",
    "unique_nodes = np.unique(elem_nodes) # sorted unique nodes\n",
    "mapped_triangle = np.searchsorted(unique_nodes, elem_nodes) # indices of the nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5d1341-e044-48e7-b896-376a0e60a958",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_nodes[mapped_triangle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfef1688-5a92-4623-a102-982409432e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_nodes=np.concatenate(node_coords[elem_nodes-1], axis=0)\n",
    "lat_nodes=concat_nodes[:,1]\n",
    "lon_nodes=concat_nodes[:,0]\n",
    "\n",
    "df_nodes=pd.DataFrame({'Lon': lon_nodes, 'Lat': lat_nodes})\n",
    "df_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f37d6c9-0dd0-4271-9a5b-effbf5c3446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disabled for now. It's not particularly useful\n",
    "\n",
    "# # Create a base map centered on the first coordinate\n",
    "# map_center = [stations_df['lat'].iloc[0], stations_df['lng'].iloc[0]]\n",
    "# my_map = folium.Map(location=map_center, zoom_start=8)\n",
    "\n",
    "# # Add markers for each coordinate\n",
    "# for index, row in df_nodes.iterrows():\n",
    "#     folium.CircleMarker(\n",
    "#         location=[row['Lat'], row['Lon']],\n",
    "#     ).add_to(my_map)\n",
    "\n",
    "# for index, row in stations_df.iterrows():\n",
    "#     folium.CircleMarker(\n",
    "#         location=[row['lat'], row['lng']],\n",
    "#         popup=row['id'], color='red'\n",
    "#     ).add_to(my_map)\n",
    "\n",
    "# tile = folium.TileLayer(\n",
    "#         tiles = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "#         attr = 'Esri',\n",
    "#         name = 'Esri Satellite',\n",
    "#         overlay = False,\n",
    "#         control = True\n",
    "#        ).add_to(my_map)\n",
    "\n",
    "# # Save the map to an HTML file\n",
    "# # my_map.save(\"nodesmap.html\")\n",
    "\n",
    "# my_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795ebcff-c865-4b88-b8eb-eb06def60374",
   "metadata": {},
   "source": [
    "### Calculate CORA water levels\n",
    "\n",
    "**Average the water levels at the 3 nodes of the element containing the station coordinates for the selected time period. Append these CORA values as new columns to the dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5mLkwjTrTtK9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "5mLkwjTrTtK9",
    "outputId": "40895ce6-9bb8-4d6a-8219-328ef3f204a9"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "start_t = f'{start_year}-{start_month}-{start_day} 00:00:00'\n",
    "end_t = f'{end_year}-{end_month}-{end_day} 23:00:00'\n",
    "dt_range=pd.date_range(start_t, end_t, freq='h',inclusive='both')\n",
    "\n",
    "num_ts = len(dt_range) # number of time samples\n",
    "t = np.zeros((num_ts, 3), dtype=float) # preallocate with zeros\n",
    "zeta_point = np.zeros((num_ts), dtype=float) # preallocate with zeros\n",
    "mean_zeta = np.zeros((num_ts,len(stations_df)), dtype=float)\n",
    "\n",
    "# for i in range(0,len(stations_df)):\n",
    "for i in tqdm(range(len(stations_df)), desc=\"Processing stations\"):\n",
    "    zeta_tslice = ds[\"zeta\"].sel(time=slice(start_t, end_t), node=unique_nodes[mapped_triangle[i]]-1).compute()\n",
    "    t = zeta_tslice.values * weights[i]\n",
    "    zeta_point = np.sum(t, axis=1) / np.sum(weights[i])\n",
    "    mean_zeta_i = np.nanmean(zeta_tslice.values, axis=1)\n",
    "\n",
    "    zeta_point[np.isnan(zeta_point)] = mean_zeta_i[np.isnan(zeta_point)]\n",
    "\n",
    "    df['cora_'+stations_df.iloc[i,0]] = zeta_point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b692a4-f2fb-4b54-b611-92706cefe2a5",
   "metadata": {},
   "source": [
    "## Plot the data\n",
    "\n",
    "**Plot the time series data for the NWLON observations and CORA for comparison.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RoWce5cCwoX6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 957
    },
    "id": "RoWce5cCwoX6",
    "outputId": "a992630f-012e-44bc-b60f-c2c19095c233"
   },
   "outputs": [],
   "source": [
    "ylabel = \"MSL, m\"\n",
    "# num_plots = min(zeta_df.shape[1], len(stations_df))\n",
    "for i in range(0,len(stations_df)):\n",
    "  # Create title using both station ID and name\n",
    "  station_id = stations_df.iloc[i, 0]  # id column\n",
    "  station_name = stations_df.iloc[i, 1]  # name column\n",
    "  title = f\"Hourly Water Levels for {station_name}: {station_id}\"\n",
    "\n",
    "  # Create larger figure\n",
    "  plt.figure(figsize=(15, 8))\n",
    "  df[['tnc_'+stations_df.id.iloc[i],'cora_'+stations_df.iloc[i,0]]].plot(figsize=(15, 8))\n",
    "\n",
    "  plt.title(title, fontsize=14, fontweight='bold')\n",
    "  plt.xlabel('Date/Time (GMT)', fontsize=12)\n",
    "  plt.ylabel(ylabel, fontsize=12)\n",
    "\n",
    "  # Improve datetime label formatting\n",
    "  plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "  # Add grid for better readability\n",
    "  plt.grid(True, alpha=0.3)\n",
    "\n",
    "  # Add legend with better positioning\n",
    "  plt.legend(['TNC Observed', 'CORA Model'], loc='best')\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.savefig(f\"{station_id}_water_levels.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
